{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c84e9c3f-6e8c-4979-bba0-2829c24abcc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Dataset Shape: (50000, 2)\n",
      "Columns: ['review', 'sentiment']\n",
      "\n",
      "First few rows:\n",
      "                                              review sentiment\n",
      "0  One of the other reviewers has mentioned that ...  positive\n",
      "1  A wonderful little production. <br /><br />The...  positive\n",
      "2  I thought this was a wonderful way to spend ti...  positive\n",
      "3  Basically there's a family where a little boy ...  negative\n",
      "4  Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
      "\n",
      "Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   review     50000 non-null  object\n",
      " 1   sentiment  50000 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 781.4+ KB\n",
      "None\n",
      "\n",
      "Class Distribution:\n",
      "sentiment\n",
      "positive    25000\n",
      "negative    25000\n",
      "Name: count, dtype: int64\n",
      "DATA QUALITY ASSESSMENT\n",
      "==================================================\n",
      "\n",
      "Missing Values:\n",
      "review       0\n",
      "sentiment    0\n",
      "dtype: int64\n",
      "\n",
      "Duplicate Records: 418\n",
      "Duplicate Reviews (based on text): 418\n",
      "\n",
      "Sample Review (showing noise):\n",
      "One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. They are right, as this is exactly what happened with me.<br /><br />The first thing that struck me about Oz was its brutality and unflinching scenes of violence, which set in right from the word GO. Trust me, this is not a show for the faint hearted or timid. This show pulls no punches with regards to drugs, sex or violence. Its is hardcore, in the classic use of the word.<br /><br />It is called OZ\n",
      "\n",
      "==================================================\n",
      "APPLYING DATA CLEANING\n",
      "==================================================\n",
      "\n",
      "Cleaning text data...\n",
      "\n",
      "Before Cleaning:\n",
      "One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. They are right, as this is exactly what happened with me.<br /><br />The first thing that struck me about Oz was its brutality and unflinching scenes of violence, which set in right from the word GO. Tru\n",
      "\n",
      "After Cleaning:\n",
      "one of the other reviewers has mentioned that after watching just oz episode you ll be hooked they are right as this is exactly what happened with me the first thing that struck me about oz was its brutality and unflinching scenes of violence which set in right from the word go trust me this is not \n",
      "\n",
      "Removing duplicate records...\n",
      "Records removed: 423\n",
      "Dataset shape after removing duplicates: (49577, 3)\n",
      "APPLYING DATA REDUCTION (STRATIFIED SAMPLING)\n",
      "==================================================\n",
      "\n",
      "Original dataset size: 49577\n",
      "Sample size (20.0%): 9915\n",
      "Original class distribution:\n",
      "sentiment\n",
      "positive    24882\n",
      "negative    24695\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Class proportions:\n",
      "sentiment\n",
      "positive    0.501886\n",
      "negative    0.498114\n",
      "Name: count, dtype: float64\n",
      "\n",
      "Sampled dataset shape: (9914, 3)\n",
      "\n",
      "Sampled class distribution:\n",
      "sentiment\n",
      "positive    4976\n",
      "negative    4938\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Original proportions:\n",
      "sentiment\n",
      "positive    0.501886\n",
      "negative    0.498114\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Sampled proportions:\n",
      "sentiment\n",
      "positive    0.501916\n",
      "negative    0.498084\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "==================================================\n",
      "SAVING PREPROCESSED DATA\n",
      "==================================================\n",
      "\n",
      "Cleaned full dataset saved as 'IMDB_cleaned_full.csv'\n",
      "==================================================\n",
      "Original dataset size: 50,000 records\n",
      "After duplicate removal: 49577 records\n",
      "Sampled dataset size: 9914 records\n",
      "Data reduction: 80.00%\n",
      "\n",
      "Preprocessing completed successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries \n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import re \n",
    "from sklearn.model_selection import train_test_split\n",
    "# Load the IMDB dataset print(\"Loading IMDB   Dataset...\") \n",
    "df = pd.read_csv('IMDB_Dataset.csv')\n",
    "# Display initial dataset information \n",
    "print(f\"Initial Dataset Shape: {df.shape}\")\n",
    "print(f\"Columns: {df.columns.tolist()}\") \n",
    "print(f\"\\nFirst few rows:\") \n",
    "print(df.head()) \n",
    "print(f\"\\nDataset Info:\")\n",
    "print(df.info()) \n",
    "print(f\"\\nClass Distribution:\") \n",
    "print(df['sentiment'].value_counts())\n",
    "\n",
    "# Check for missing values print(\"\\n\" + \"=\"*50) \n",
    "print(\"DATA QUALITY ASSESSMENT\") \n",
    "print(\"=\"*50) \n",
    "print(f\"\\nMissing Values:\") \n",
    "print(df.isnull().sum())\n",
    "# Check for duplicate records \n",
    "print(f\"\\nDuplicate Records: {df.duplicated().sum()}\") \n",
    "print(f\"Duplicate Reviews (based on text): {df.duplicated(subset=['review']).sum()}\")\n",
    "# Display sample noisy data\n",
    "print(f\"\\nSample Review (showing noise):\")\n",
    "print(df['review'].iloc[0][:500])  # First 500 characters\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# DATA CLEANING - TECHNIQUE 1 \n",
    "# ============================================\n",
    "def clean_text(text):     \n",
    " \"\"\"  Clean text data by removing noise and normalizing         \n",
    "        Steps:\n",
    "1.\tConvert to lowercase\n",
    "2.\tRemove HTML tags\n",
    "3.\tRemove URLs\n",
    "4.\tRemove special characters and numbers\n",
    "5.\tRemove extra whitespace    \"\"\"    \n",
    " # Convert to lowercase     \n",
    " text = text.lower()         \n",
    " # Remove HTML tags     \n",
    " text = re.sub(r'<.*?>', '', text)         \n",
    " # Remove URLs     \n",
    " text = re.sub(r'http\\S+|www\\S+', '', text)     \n",
    " # Remove special characters and numbers, keep only letters and spaces     \n",
    " text = re.sub(r'[^a-z\\s]', ' ', text)         \n",
    " # Remove extra whitespace\n",
    " text = re.sub(r'\\s+', ' ', text).strip()         \n",
    " return text\n",
    "# Apply text cleaning \n",
    "print(\"\\n\" + \"=\"*50) \n",
    "print(\"APPLYING DATA CLEANING\") \n",
    "print(\"=\"*50) \n",
    "print(\"\\nCleaning text data...\") \n",
    "df['cleaned_review'] = df['review'].apply(clean_text)\n",
    "# Display before and after cleaning \n",
    "print(\"\\nBefore Cleaning:\")\n",
    "print(df['review'].iloc[0][:300]) \n",
    "print(\"\\nAfter Cleaning:\") \n",
    "print(df['cleaned_review'].iloc[0][:300])\n",
    "# Remove duplicate records \n",
    "print(f\"\\nRemoving duplicate records...\") \n",
    "initial_size = len(df) \n",
    "df = df.drop_duplicates(subset=['cleaned_review'], keep='first') \n",
    "final_size = len(df) \n",
    "print(f\"Records removed: {initial_size - final_size}\") \n",
    "print(f\"Dataset shape after removing duplicates: {df.shape}\")\n",
    "# Reset index after removing duplicates \n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# DATA REDUCTION - TECHNIQUE 2: STRATIFIED SAMPLING # ============================================\n",
    "def stratified_sampling(dataframe, sample_size, class_column):    \n",
    "    \"\"\"\n",
    "    Perform stratified sampling to maintain class distribution\n",
    "        Parameters:\n",
    "-\tdataframe: Input DataFrame\n",
    "-\tsample_size: Total number of samples to draw\n",
    "-\tclass_column: Column name containing class labels\n",
    "        Returns:\n",
    "-\tSampled DataFrame with preserved class distribution\n",
    "    \"\"\"     \n",
    "    # Calculate samples per class (proportional sampling)    \n",
    "    class_counts = dataframe[class_column].value_counts()    \n",
    "    class_proportions = class_counts / len(dataframe)         \n",
    "    print(f\"Original class distribution:\")     \n",
    "    print(class_counts)     \n",
    "    print(f\"\\nClass proportions:\")     \n",
    "    print(class_proportions)         \n",
    "    # Sample from each class proportionally    \n",
    "    sampled_dfs = []     \n",
    "    for class_label, proportion in class_proportions.items():         \n",
    "        class_sample_size = int(sample_size * proportion)         \n",
    "        class_df = dataframe[dataframe[class_column] == class_label]         \n",
    "        class_sample = class_df.sample(n=class_sample_size, random_state=42)        \n",
    "        sampled_dfs.append(class_sample)         \n",
    "\n",
    "    # Combine samples from all classes     \n",
    "    sampled_df = pd.concat(sampled_dfs, ignore_index=True)         \n",
    "\n",
    "    # Shuffle the combined sample     \n",
    "    sampled_df = sampled_df.sample(frac=1, random_state=42).reset_index(drop=True)         \n",
    "    return sampled_df\n",
    "# Apply stratified sampling print(\"\\n\" + \"=\"*50) \n",
    "print(\"APPLYING DATA REDUCTION (STRATIFIED SAMPLING)\") \n",
    "print(\"=\"*50)\n",
    "# Define sample size (e.g., 20% of original data) \n",
    "sample_percentage = 0.2 \n",
    "sample_size = int(len(df) * sample_percentage)\n",
    "print(f\"\\nOriginal dataset size: {len(df)}\")\n",
    "print(f\"Sample size ({sample_percentage*100}%): {sample_size}\")\n",
    "# Perform stratified sampling \n",
    "df_sampled = stratified_sampling(df, sample_size, 'sentiment')\n",
    "print(f\"\\nSampled dataset shape: {df_sampled.shape}\")\n",
    "print(f\"\\nSampled class distribution:\")\n",
    "print(df_sampled['sentiment'].value_counts())\n",
    "# Verify proportions are maintained \n",
    "print(f\"\\nOriginal proportions:\") \n",
    "print(df['sentiment'].value_counts(normalize=True)) \n",
    "print(f\"\\nSampled proportions:\")\n",
    "print(df_sampled['sentiment'].value_counts(normalize=True))\n",
    "\n",
    "\n",
    "# Save cleaned full dataset \n",
    "print(\"\\n\" + \"=\"*50) \n",
    "print(\"SAVING PREPROCESSED DATA\") \n",
    "print(\"=\"*50) \n",
    "df.to_csv('IMDB_cleaned_full.csv', index=False)\n",
    "print(\"\\nCleaned full dataset saved as 'IMDB_cleaned_full.csv'\")\n",
    "# Save sampled dataset df_sampled.to_csv('IMDB_cleaned_sampled.csv', index=False) print(\"Sampled dataset saved as 'IMDB_cleaned_sampled.csv'\")\n",
    "# Summary statistics print(\"\\n\" + \"=\"*50) print(\"PREPROCESSING SUMMARY\") \n",
    "print(\"=\"*50) \n",
    "print(f\"Original dataset size: 50,000 records\") \n",
    "print(f\"After duplicate removal: {len(df)} records\") \n",
    "print(f\"Sampled dataset size: {len(df_sampled)} records\") \n",
    "print(f\"Data reduction: {(1 - len(df_sampled)/len(df))*100:.2f}%\") \n",
    "print(\"\\nPreprocessing completed successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
